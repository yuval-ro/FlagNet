{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4dfb1-584f-4c6e-b39a-c32fc1863ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing Modules'''\n",
    "\n",
    "'''\n",
    "Prerequisites:\n",
    "NumPy             https://numpy.org/doc/stable/\n",
    "Matplotlib        https://matplotlib.org/stable/index.html\n",
    "PyTorch           https://pytorch.org/docs/stable/index.html\n",
    "Torchvision       https://pytorch.org/docs/stable/index.html\n",
    "PIL               https://pillow.readthedocs.io/en/stable/\n",
    "GitPython         https://gitpython.readthedocs.io/en/stable/\n",
    "split-folders:    https://pypi.org/project/split-folders/\n",
    "python-dotenv:    https://pypi.org/project/python-dotenv/\n",
    "'''\n",
    "\n",
    "# vanilla:\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from time import strptime\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import sys\n",
    "# external:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import PIL.Image as Image\n",
    "import git\n",
    "import splitfolders\n",
    "from dotenv import load_dotenv\n",
    "# custom:\n",
    "from routines import *\n",
    "from displays import *\n",
    "import myTransforms\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fa87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Cloning the Remote Data-Repository'''\n",
    "\n",
    "\n",
    "bad_repo_url = False\n",
    "# Load the required .env file:\n",
    "if not load_dotenv('./.env'):\n",
    "    raise FileNotFoundError('cannot find the required .env file')\n",
    "# Clone the data repo\n",
    "gh_token = os.getenv('GH_TOKEN')\n",
    "gh_username = os.getenv('GH_USERNAME')\n",
    "remote_repo_name = os.getenv('REMOTE_REPO_NAME')\n",
    "local_repo_name = remote_repo_name\n",
    "remote_repo_url = f'https://{gh_token}@github.com/{gh_username}/{remote_repo_name}.git'\n",
    "# Checks if a leftover repo already exists, if so will overwrite it:\n",
    "if os.path.exists(local_repo_name):\n",
    "    git.rmtree(local_repo_name)\n",
    "# Clones the repo, will raise an exception if the remote URL is corrupted\n",
    "try:\n",
    "    git.Repo.clone_from(remote_repo_url, local_repo_name)\n",
    "except Exception as e:\n",
    "    bad_repo_url=True\n",
    "    pass\n",
    "if bad_repo_url:\n",
    "    e_msg='bad remote repository URL'\n",
    "    raise SystemExit(e_msg)\n",
    "dataset_path = local_repo_name + '\\\\dataset'\n",
    "classes_path = local_repo_name + '\\\\classes.json'\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a22b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parsing the JSON File from the Data Repository'''\n",
    "\n",
    "\n",
    "json_not_found = False\n",
    "try:\n",
    "    with open(classes_path, 'r') as f:\n",
    "        json_file = json.load(f)\n",
    "        classes = OrderedDict(json_file[0])\n",
    "        images_per_class = json_file[1]['images_per_class']\n",
    "        # Create a list of all subdirs of dataset dir:\n",
    "        dir_names = [dataset_path + '\\\\%.2d' % i for i in range(1, len(classes) + 1)]\n",
    "    # Displays the JSON file metadata:\n",
    "    println(['total classes', 'images per class'], header=True)\n",
    "    println([len(classes), images_per_class])\n",
    "except FileNotFoundError as e:\n",
    "    json_not_found=True\n",
    "if json_not_found:\n",
    "    e_msg=f'cannot locate the \"classes.json\" file in \"{local_repo_name}\".'\\\n",
    "        + f'\\nre-run \\'Data Repository Cloning\\' cell and try again!'\n",
    "    raise SystemExit(e_msg)\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a41e81-7b80-4b39-be79-c40461103f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Validating the Dataset Directory'''\n",
    "\n",
    "\n",
    "println([('performing a valdiation of the repo according to the JSON file,\\n\\\n",
    "before any further training can take place...', 'y')])\n",
    "\n",
    "files_per_class = []\n",
    "bad_dirs = []\n",
    "json_ne_dirs = False\n",
    "\n",
    "# Validates the number of classes defined in the JSON equals to number of classes subdirs:\n",
    "if len(os.listdir(dataset_path)) != len(classes):\n",
    "    json_ne_dirs=True\n",
    "\n",
    "# Validates that the number of images in each class subdir equals to the one defined in the JSON:\n",
    "for dir_tuple in os.walk(dataset_path):\n",
    "    if dir_tuple[0] in dir_names: # skips junk directories\n",
    "        images_in_dir = len(dir_tuple[2])\n",
    "        files_per_class.append(images_in_dir)\n",
    "        if images_in_dir != images_per_class:\n",
    "            bad_dirs.append(dir_tuple[0])\n",
    "\n",
    "# Raise exceptions if needed:\n",
    "if json_ne_dirs:\n",
    "    e_msg=f'number of classes according to the JSON file ({len(classes)})'\\\n",
    "        + f' does not correlate with total dirs ({len(os.listdir(dataset_path))})'\\\n",
    "        + f' in \\\"{dataset_path}\\\".'\\\n",
    "        + f'\\nre-run \\'Data Repository Cloning\\' cell then re-run this cell.'\n",
    "    raise SystemExit(e_msg)\n",
    "elif bad_dirs != []:\n",
    "    e_msg=f'image count in the following directories is incorrect: {bad_dirs}'\n",
    "    raise SystemExit(e_msg)\n",
    "\n",
    "# If the number of files found in a class subdir does not strictly equal\n",
    "#  to the defined number (from the JSON file), the number will be highlighted\n",
    "#  with red color; elsewise, in green.\n",
    "println(['id', 'parsed class', 'images found'], header=True)\n",
    "for i, (ID, Class) in enumerate(classes.items()):\n",
    "\n",
    "    println([ID,\n",
    "            Class.upper() if Class in ['uk','usa'] else Class.capitalize(),\n",
    "            (files_per_class[i], ('g' if files_per_class[i] == images_per_class else 'r'))])\n",
    "println(['','','total images'], header=True)\n",
    "println(['','',(sum(files_per_class), ('g' if (sum(files_per_class) == (len(classes) * images_per_class)) else 'r'))])\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a462ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Splitting the Dataset'''\n",
    "\n",
    "\n",
    "println([('creating a new \\'sets\\' dir, with three subdirs of images: \\\n",
    "\\'train\\', \\'valid\\', \\'test\\'...', 'y')])\n",
    "\n",
    "# Deleting a leftover 'sets' directory if such exists:\n",
    "sets_path = 'sets'\n",
    "if os.path.exists(sets_path):\n",
    "    shutil.rmtree(sets_path)\n",
    "\n",
    "# Randomly splitting the dataset into 'test', 'valid', 'test' image directories:\n",
    "try:\n",
    "    splitfolders.ratio(\n",
    "        dataset_path,\n",
    "        output=sets_path,\n",
    "        seed=1337,\n",
    "        ratio=(.8, .1, .1),\n",
    "        group_prefix=None,\n",
    "        move=False)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Defining the paths for the subdirs:\n",
    "train_set_path = sets_path + '\\\\train'\n",
    "valid_set_path = sets_path + '\\\\val'\n",
    "test_set_path = sets_path + '\\\\test'\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83746019",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating DataLoaders'''\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "print(f'batch size is {batch_size}')\n",
    "\n",
    "# Instanciating each set:\n",
    "train_data = datasets.ImageFolder(train_set_path, transform=myTransforms.train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_set_path, transform=myTransforms.valid_transforms)\n",
    "test_data = datasets.ImageFolder(test_set_path, transform=myTransforms.test_transforms)\n",
    "\n",
    "# Creating a DataLoader for each set:\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffdceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Instaciating a Model and a Classifier'''\n",
    "\n",
    "\n",
    "pretrained = True\n",
    "weights=('DEFAULT' if pretrained else None)\n",
    "model = models.vgg16(weights=weights)\n",
    "model_name = 'VGG16'\n",
    "for param in model.parameters():\n",
    "    # Freeze the MODEL parameters so we don't backprop through them! Only through the classifier.\n",
    "    param.requires_grad = False\n",
    "dropout_probability = .5\n",
    "in_features = 25088\n",
    "out_features = 1024\n",
    "od = OrderedDict([('fc1', nn.Linear(in_features, out_features)),\n",
    "                ('drop', nn.Dropout(p=dropout_probability)),\n",
    "                ('relu', nn.ReLU()),\n",
    "                ('fc2', nn.Linear(out_features, len(classes))),\n",
    "                ('output', nn.LogSoftmax(dim=1))])\n",
    "classifier = nn.Sequential(od)\n",
    "model.classifier = classifier\n",
    "\n",
    "println(['Model'], header=True)\n",
    "println([f'{model_name}, ' + ('Pretrained ' if pretrained else 'Not Pretrained')])\n",
    "println(['Classifier'], header=True)\n",
    "print([f'{layer}' for layer in od.keys()])\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading a Model Checkpoint'''\n",
    "\n",
    "println([('looking for \\'.pth\\' files in root, will load the latest one; \\\n",
    "if none were found it is still OK...', 'y')])\n",
    "\n",
    "# Template for loading a checkpoint:\n",
    "def load_checkpoint(file_path):\n",
    "    checkpoint = torch.load(file_path)\n",
    "    learning_rate = checkpoint['learning_rate']\n",
    "    model = getattr(torchvision.models, checkpoint['network'])(weights=weights)\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.epochs = checkpoint['epochs']\n",
    "    model.optimizer = checkpoint['optimizer']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Sort all checkpoints in root dir by their filename, which tells their creation date (ascending order):\n",
    "timestamp_format = '%H%M%S_%d%m%y'\n",
    "checkpoints = []\n",
    "for i in os.listdir():\n",
    "    if i.endswith('.pth'):\n",
    "        filename, ext = os.path.splitext(i)\n",
    "        filename_date_tuple = (time.strptime(filename, timestamp_format), i)\n",
    "        checkpoints.append(filename_date_tuple)\n",
    "\n",
    "# TODO: add a print for loading a cp\n",
    "\n",
    "if checkpoints != []:\n",
    "    # Get the latest checkpoint and load it onto the model instance\n",
    "    latest_checkpoint = (sorted(checkpoints, key=lambda x: x[0])[-1])[1]\n",
    "    model = load_checkpoint(latest_checkpoint)\n",
    "    print(f'checkpoint loaded from: {latest_checkpoint}')\n",
    "else:\n",
    "    print('no \\'.pth\\' files were found.')\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defining the Training Hyperparameters'''\n",
    "\n",
    "\n",
    "# Hyperparameters:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 10\n",
    "learning_rate = .001\n",
    "criterion = nn.NLLLoss()\n",
    "# Only train the CLASSIFIER parameters, FEATURE parameters are frozen!\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr = learning_rate)\n",
    "# Casting the model instance to the available hardware:\n",
    "model.to(device)\n",
    "# Hyperparameters names for displaying:\n",
    "device_name = ('GPU' if device == torch.device('cuda') else 'CPU')\n",
    "criterion_name = 'Negative Log Loss'\n",
    "optimizer_name = 'Adam'\n",
    "# Displaying:\n",
    "println(['model', 'pretrained', 'device', 'epochs'], header=True)\n",
    "println([model_name, ('yes' if model_is_pretrained else 'no'), \n",
    "        (device_name, ('g' if device_name == 'GPU' else 'r')), epochs])\n",
    "println(['learning rate', 'loss function', 'optimizer'], header=True)\n",
    "println([learning_rate, criterion_name, optimizer_name])\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model Training, Validation, and Testing'''\n",
    "\n",
    "\n",
    "println([(f'training on {device_name} started...', 'y')])\n",
    "\n",
    "\n",
    "# Training and validating part:\n",
    "train_metadata = []\n",
    "start_training_time = time.time()\n",
    "println(['epoch', 'time', 'train loss', 'valid loss', 'accuracy'], header=True)\n",
    "for idx in range(epochs):\n",
    "    # Keep the model object up-to-date (because we send it to another function):\n",
    "    hyperparams = (model, optimizer, device, criterion)\n",
    "    # Epoch metadata:\n",
    "    start_time = time.time()\n",
    "    end_time = None\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    accuracy = 0\n",
    "    # Switching model mode to TRAINING:\n",
    "    model.train()\n",
    "    # Training the model using the entire train image set:\n",
    "    for inputs, labels in train_loader:     \n",
    "        train_loss += train(hyperparams, inputs, labels)\n",
    "    # Switching model mode to EVALUATION:\n",
    "        model.eval()\n",
    "    # Validating the model using the entire valid image set:\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            loss, acc = test(hyperparams, inputs, labels)\n",
    "            valid_loss += loss\n",
    "            accuracy += acc\n",
    "    end_time = time.time()\n",
    "    aggregated_metadata = (idx, start_time, end_time, train_loss, valid_loss, accuracy, (train_loader, valid_loader))\n",
    "    # Collect this epoch's metadata and add to the list list:\n",
    "    collect(train_metadata, aggregated_metadata)\n",
    "    # Display this epoch's metadata:\n",
    "    displayTrain(train_metadata, idx)\n",
    "end_training_time = time.time()\n",
    "total_training_time = (end_training_time - start_training_time )\n",
    "# Displaying the collected training metadata:\n",
    "println([(f'training finished, results:', 'y')])\n",
    "displayTrain(train_metadata)\n",
    "\n",
    "\n",
    "# Testing part:\n",
    "println([(f'testing the trained model:', 'y')])\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "# Testing loop:\n",
    "model.eval()\n",
    "hyperparams = (model, optimizer, device, criterion)\n",
    "for inputs, labels in test_loader:\n",
    "    loss, acc = test(hyperparams, inputs, labels)\n",
    "    test_loss += loss\n",
    "    accuracy += acc\n",
    "displayTest(test_loss, accuracy, test_loader)\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cdd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Saving a Model Checkpoint'''\n",
    "\n",
    "\n",
    "println([('saving a new \\'.pth\\' file with a timestamp of current time...', 'y')])\n",
    "\n",
    "timestamp_format = '%H%M%S_%d%m%y'\n",
    "timestamp = datetime.datetime.now().strftime(timestamp_format)\n",
    "checkpoint_name = f'{timestamp}.pth'\n",
    "model.class_to_idx = train_data.class_to_idx\n",
    "checkpoint = {'network': 'vgg16',\n",
    "              'input_size': in_features,\n",
    "              'output_size': len(classes),\n",
    "              'learning_rate': learning_rate,       \n",
    "              'batch_size': batch_size,\n",
    "              'classifier' : classifier,\n",
    "              'epochs': epochs,\n",
    "              'optimizer': optimizer.state_dict(),\n",
    "              'state_dict': model.state_dict(),\n",
    "              'class_to_idx': model.class_to_idx}\n",
    "torch.save(checkpoint, checkpoint_name)\n",
    "checkpoint_path = os.path.abspath(os.getcwd()) + '\\\\' + checkpoint_name\n",
    "print(f'checkpoint saved to \\\"{checkpoint_path}\\\"')\n",
    "\n",
    "println([('done.', 'g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_image(pil_image):\n",
    "#     ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "#         returns an Numpy array\n",
    "#     '''\n",
    "    \n",
    "#     img_loader = transforms.Compose([transforms.Resize(size_resize),\n",
    "#                                      transforms.CenterCrop(size_crop), \n",
    "#                                      transforms.ToTensor()])\n",
    "    \n",
    "#     #pil_image = Image.open(image)\n",
    "#     pil_image = img_loader(pil_image).float()\n",
    "    \n",
    "#     np_image = np.array(pil_image)    \n",
    "    \n",
    "#     mean = np.array(normalize_mean)\n",
    "#     std = np.array(normalize_std)\n",
    "#     np_image = (np.transpose(np_image, (1, 2, 0)) - mean) / std    \n",
    "#     np_image = np.transpose(np_image, (2, 0, 1))\n",
    "            \n",
    "#     return np_image\n",
    "\n",
    "# def imshow(np_image, ax = None, title = None):\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots()\n",
    "    \n",
    "#     # PyTorch tensors assume the color channel is the first dimension\n",
    "#     # but matplotlib assumes is the third dimension\n",
    "#     np_image = np.transpose(np_image, (1, 2, 0))\n",
    "    \n",
    "#     # Undo preprocessing\n",
    "#     mean = np.array(normalize_mean)\n",
    "#     std = np.array(normalize_std)\n",
    "#     np_image = std * np_image + mean\n",
    "    \n",
    "#     # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "#     np_image = np.clip(np_image, 0, 1)\n",
    "    \n",
    "#     ax.imshow(np_image)\n",
    "    \n",
    "#     return ax\n",
    "\n",
    "\n",
    "# images_paths = result = [os.path.join(dp, f) for dp, dn, filenames in os.walk(sets_path) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "# random.seed()\n",
    "# random_image_path = random.choice(images_paths)\n",
    "# random_image = Image.open(random_image_path)\n",
    "# imshow(process_image(random_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa56993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the class from an image file:\n",
    "\n",
    "# def predict(pil_image, model, top_k_probabilities = 5):\n",
    "#     ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "#     '''\n",
    "    \n",
    "#     # Use GPU if it's available\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     #print(device)\n",
    "\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "    \n",
    "#     np_image = process_image(pil_image)\n",
    "#     tensor_image = torch.from_numpy(np_image)\n",
    "    \n",
    "#     inputs = Variable(tensor_image)\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         inputs = Variable(tensor_image.float().cuda())           \n",
    "        \n",
    "#     inputs = inputs.unsqueeze(dim = 0)\n",
    "#     log_probabilities = model.forward(inputs)\n",
    "#     probabilities = torch.exp(log_probabilities)    \n",
    "\n",
    "#     top_probabilities, top_classes = probabilities.topk(top_k_probabilities, dim = 1)\n",
    "#     #print(top_probabilities)\n",
    "#     #print(top_classes)\n",
    "    \n",
    "#     class_to_idx_inverted = {model.class_to_idx[c]: c for c in model.class_to_idx}\n",
    "#     top_mapped_classes = list()\n",
    "    \n",
    "#     for label in top_classes.cpu().detach().numpy()[0]:\n",
    "#         top_mapped_classes.append(class_to_idx_inverted[label])\n",
    "    \n",
    "#     return top_probabilities.cpu().detach().numpy()[0], top_mapped_classes\n",
    "\n",
    "# # with open(classes_json, 'r') as f:\n",
    "# #     category_label_to_name = json.load(f)\n",
    "\n",
    "# top_probabilities, top_classes = predict(random_image, model, top_k_probabilities = 5)\n",
    "\n",
    "# for c in top_classes:\n",
    "#     if int(c) < 10: # overcome the '0' padding in the filename\n",
    "#         c = str(int(c))\n",
    "#     print(classes[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display an image along with the top 5 classes\n",
    "\n",
    "# max_index = np.argmax(top_probabilities)\n",
    "# max_probability = top_probabilities[max_index]\n",
    "# label = top_classes[max_index]\n",
    "\n",
    "# if int(label) < 10: # overcome the '0' padding in the filename\n",
    "#     label = str(int(label))\n",
    "\n",
    "# fig = plt.figure(figsize=(6,6))\n",
    "# ax1 = plt.subplot2grid((15,9), (0,0), colspan = 9, rowspan = 9)\n",
    "# ax2 = plt.subplot2grid((15,9), (9,2), colspan = 5, rowspan = 5)\n",
    "\n",
    "# ax1.axis('off')\n",
    "# ax1.set_title(classes[label])\n",
    "# ax1.imshow(random_image)\n",
    "\n",
    "# labels = []\n",
    "# for c in top_classes:\n",
    "#     if int(c) < 10: # overcome the '0' padding in the filename\n",
    "#         c = str(int(c))\n",
    "#     labels.append(classes[c])\n",
    "\n",
    "# y_pos = np.arange(5)\n",
    "# ax2.set_yticks(y_pos)\n",
    "# ax2.set_yticklabels(labels)\n",
    "# ax2.set_xlabel('Probability')\n",
    "# ax2.invert_yaxis()\n",
    "# ax2.barh(y_pos, top_probabilities, xerr = 0, align = 'center', color = 'blue')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check - display an image along with the top 5 classes\n",
    "\n",
    "# test_case = 10\n",
    "\n",
    "# for i in range(test_case):\n",
    "#     random.seed()\n",
    "#     random_class_path = random.choice(os.listdir(test_set_path))\n",
    "#     random.seed()\n",
    "#     random_image_path = test_set_path + '\\\\' + random_class_path + '\\\\' + random.choice(os.listdir(test_set_path + '\\\\' + random_class_path))\n",
    "\n",
    "#     pil_image = Image.open(random_image_path)\n",
    "#     plt.imshow(pil_image)\n",
    "\n",
    "#     top_probabilities, top_classes = predict(pil_image, model, top_k_probabilities = 5)\n",
    "#     max_index = np.argmax(top_probabilities)\n",
    "#     max_probability = top_probabilities[max_index]\n",
    "#     label = top_classes[max_index]\n",
    "\n",
    "#     fig = plt.figure(figsize=(6,6))\n",
    "#     ax1 = plt.subplot2grid((15,9), (0,0), colspan = 9, rowspan = 9)\n",
    "#     ax2 = plt.subplot2grid((15,9), (9,2), colspan = 5, rowspan = 5)\n",
    "\n",
    "#     ax1.axis('off')\n",
    "#     ax1.set_title(classes[flower_class]) #Real class\n",
    "#     ax1.imshow(pil_image)\n",
    "\n",
    "#     labels = []\n",
    "#     for c in top_classes:\n",
    "#         if int(c) < 10: # overcome the '0' padding in the filename\n",
    "#             c = str(int(c))\n",
    "#         labels.append(classes[c])\n",
    "\n",
    "#     y_pos = np.arange(5)\n",
    "#     ax2.set_yticks(y_pos)\n",
    "#     ax2.set_yticklabels(labels)\n",
    "#     ax2.set_xlabel('Probability')\n",
    "#     ax2.invert_yaxis()\n",
    "#     ax2.barh(y_pos, top_probabilities, xerr = 0, align = 'center', color = 'blue')\n",
    "\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
